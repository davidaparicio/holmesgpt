# Loki Configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: loki-config
data:
  loki.yaml: |
    auth_enabled: false
    server:
      http_listen_port: 3100
      grpc_listen_port: 9096

    ingester:
      wal:
        enabled: true
        dir: /loki/wal
      lifecycler:
        address: 127.0.0.1
        ring:
          kvstore:
            store: inmemory
          replication_factor: 1
        final_sleep: 0s
      chunk_idle_period: 1h
      max_chunk_age: 1h
      chunk_target_size: 1048576
      chunk_retain_period: 30s
      max_transfer_retries: 0

    schema_config:
      configs:
        - from: 2020-10-24
          store: boltdb-shipper
          object_store: filesystem
          schema: v11
          index:
            prefix: index_
            period: 24h

    storage_config:
      boltdb_shipper:
        active_index_directory: /loki/boltdb-shipper-active
        cache_location: /loki/boltdb-shipper-cache
        cache_ttl: 24h
        shared_store: filesystem
      filesystem:
        directory: /loki/chunks

    limits_config:
      reject_old_samples: false
      reject_old_samples_max_age: 168h
      ingestion_rate_mb: 16
      ingestion_burst_size_mb: 32

    chunk_store_config:
      max_look_back_period: 168h

    table_manager:
      retention_deletes_enabled: false
      retention_period: 168h
---
# Loki Service
apiVersion: v1
kind: Service
metadata:
  name: loki
spec:
  selector:
    app: loki
  ports:
  - name: http
    port: 3100
    targetPort: 3100
---
# Loki Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: loki
spec:
  replicas: 1
  selector:
    matchLabels:
      app: loki
  template:
    metadata:
      labels:
        app: loki
    spec:
      containers:
      - name: loki
        image: grafana/loki:2.9.0
        args:
        - -config.file=/etc/loki/loki.yaml
        ports:
        - containerPort: 3100
        volumeMounts:
        - name: config
          mountPath: /etc/loki
        - name: storage
          mountPath: /loki
        resources:
          requests:
            memory: "256Mi"
            cpu: "100m"
          limits:
            memory: "512Mi"
            cpu: "500m"
      volumes:
      - name: config
        configMap:
          name: loki-config
      - name: storage
        emptyDir: {}
---
# Historical log generator script
apiVersion: v1
kind: ConfigMap
metadata:
  name: log-generator
data:
  generate-logs.py: |
    #!/usr/bin/env python3
    import json
    import requests
    from datetime import datetime, timedelta
    import time
    import random

    LOKI_URL = "http://loki:3100/loki/api/v1/push"

    def send_logs_to_loki(logs):
        """Send logs to Loki"""
        payload = {"streams": logs}
        headers = {"Content-Type": "application/json"}

        try:
            response = requests.post(LOKI_URL, json=payload, headers=headers)
            if response.status_code != 204:
                print(f"Error sending logs: {response.status_code} - {response.text}")
            else:
                print(f"Successfully sent {len(logs)} log streams")
        except Exception as e:
            print(f"Failed to send logs: {e}")

    def generate_historical_logs():
        """Generate logs from yesterday 12 PM to 6 PM"""
        # Calculate yesterday's timestamps
        now = datetime.utcnow()
        yesterday_noon = now - timedelta(days=1)
        yesterday_noon = yesterday_noon.replace(hour=12, minute=0, second=0, microsecond=0)

        payment_service_logs = []
        payment_processor_logs = []

        # Normal operation logs (12:00 - 14:00)
        current_time = yesterday_noon
        while current_time < yesterday_noon + timedelta(hours=2):
            # Payment service normal logs
            payment_service_logs.append([
                str(int(current_time.timestamp() * 1e9)),
                f"INFO: Processing payment request for user_{random.randint(1000,9999)}"
            ])
            payment_service_logs.append([
                str(int((current_time + timedelta(seconds=1)).timestamp() * 1e9)),
                f"INFO: Payment completed successfully. Active connections: {random.randint(2,5)}/10"
            ])

            # Payment processor normal logs
            payment_processor_logs.append([
                str(int(current_time.timestamp() * 1e9)),
                f"INFO: Payment processor healthy. Queue size: {random.randint(0,5)}"
            ])

            current_time += timedelta(minutes=5)

        # Problem period (14:00 - 16:00)
        problem_start = yesterday_noon + timedelta(hours=2)
        current_time = problem_start

        # Initial spike in payment processor
        for i in range(20):
            timestamp = problem_start + timedelta(seconds=i*3)
            payment_processor_logs.append([
                str(int(timestamp.timestamp() * 1e9)),
                "INFO: Processing payment batch - unusual spike in payment volume detected"
            ])

        # Connection pool warnings and errors
        while current_time < yesterday_noon + timedelta(hours=4):
            # Connection pool filling up
            if current_time < problem_start + timedelta(minutes=5):
                connections = min(10, 7 + int((current_time - problem_start).seconds / 60))
                payment_service_logs.append([
                    str(int(current_time.timestamp() * 1e9)),
                    f"WARN: Connection pool usage high. Active connections: {connections}/10"
                ])
            else:
                # Connection pool exhausted
                payment_service_logs.append([
                    str(int(current_time.timestamp() * 1e9)),
                    "ERROR: connection pool timeout: failed to get connection from pool after 30s"
                ])
                payment_service_logs.append([
                    str(int((current_time + timedelta(seconds=1)).timestamp() * 1e9)),
                    "ERROR: Payment processing failed: connection pool timeout"
                ])
                payment_service_logs.append([
                    str(int((current_time + timedelta(seconds=2)).timestamp() * 1e9)),
                    "WARN: Active connections: 10/10 - pool exhausted"
                ])

            # Payment processor continuing to send requests
            payment_processor_logs.append([
                str(int(current_time.timestamp() * 1e9)),
                f"INFO: Processing payment for order_{random.randint(10000,99999)}"
            ])
            payment_processor_logs.append([
                str(int((current_time + timedelta(seconds=10)).timestamp() * 1e9)),
                "WARN: Payment service responding slowly"
            ])

            current_time += timedelta(minutes=2)

        # Recovery period (16:00 - 18:00)
        current_time = yesterday_noon + timedelta(hours=4)
        while current_time < yesterday_noon + timedelta(hours=6):
            connections = max(3, 10 - int((current_time - (yesterday_noon + timedelta(hours=4))).seconds / 300))
            payment_service_logs.append([
                str(int(current_time.timestamp() * 1e9)),
                f"INFO: Connection pool recovering. Active connections: {connections}/10"
            ])
            payment_processor_logs.append([
                str(int(current_time.timestamp() * 1e9)),
                "INFO: Payment processing normalized"
            ])
            current_time += timedelta(minutes=10)

        # Send to Loki
        streams = [
            {
                "stream": {
                    "namespace": "namespace-90",
                    "pod": "payment-service-abc123",
                    "container": "payment-service",
                    "app": "payment-service"
                },
                "values": payment_service_logs
            },
            {
                "stream": {
                    "namespace": "namespace-90",
                    "pod": "payment-processor-def456",
                    "container": "payment-processor",
                    "app": "payment-processor"
                },
                "values": payment_processor_logs
            }
        ]

        send_logs_to_loki(streams)
        print("Historical log generation complete!")

    if __name__ == "__main__":
        print("Waiting for Loki to be ready...")
        time.sleep(10)

        # Retry logic for Loki availability
        for i in range(5):
            try:
                generate_historical_logs()
                break
            except Exception as e:
                print(f"Attempt {i+1} failed: {e}")
                if i < 4:
                    time.sleep(10)
                else:
                    raise
---
# Job to populate historical logs
apiVersion: batch/v1
kind: Job
metadata:
  name: populate-historical-logs
spec:
  template:
    spec:
      restartPolicy: Never
      containers:
      - name: log-generator
        image: python:3.9-slim
        command: ["/bin/bash", "-c"]
        args:
          - |
            pip install requests
            python /scripts/generate-logs.py
        volumeMounts:
        - name: scripts
          mountPath: /scripts
      volumes:
      - name: scripts
        configMap:
          name: log-generator
